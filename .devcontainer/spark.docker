# Base image with Java and Ubuntu
FROM mcr.microsoft.com/devcontainers/java:11 as builder
USER root

# Set environment variables for Spark
ENV SCALA_VERSION=2.12.17 \
    SPARK_VERSION=3.3.0 \
    HADOOP_VERSION=3 \
    SPARK_HOME=/opt/spark \
    PATH="$PATH:/opt/spark/bin:/opt/spark/sbin"

# Install required tools and libraries
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    wget \
    git \
    unzip \
    python3 \
    python3-pip \
    build-essential \
    maven \
    && rm -rf /var/lib/apt/lists/*

# Install Scala
RUN curl -s https://downloads.lightbend.com/scala/${SCALA_VERSION}/scala-${SCALA_VERSION}.deb -o scala.deb && \
    dpkg -i scala.deb && rm scala.deb

# Install Spark
RUN curl -sL https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz | \
    tar -xz -C /opt && mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /opt/spark


# Apache spark environment
FROM builder as apache-spark
WORKDIR /opt/spark

ENV SPARK_MASTER_PORT=7077 \
SPARK_MASTER_WEBUI_PORT=8080 \
SPARK_LOG_DIR=/opt/spark/logs \
SPARK_MASTER_LOG=/opt/spark/logs/spark-master.out \
SPARK_WORKER_LOG=/opt/spark/logs/spark-worker.out \
SPARK_WORKER_WEBUI_PORT=8080 \
SPARK_WORKER_PORT=7000 \
SPARK_MASTER="spark://spark-master:7077" \
SPARK_WORKLOAD="master"

EXPOSE 8080 7077 6066

RUN mkdir -p $SPARK_LOG_DIR && \
touch $SPARK_MASTER_LOG && \
touch $SPARK_WORKER_LOG && \
ln -sf /dev/stdout $SPARK_MASTER_LOG && \
ln -sf /dev/stdout $SPARK_WORKER_LOG

COPY start-spark.sh /
CMD ["/bin/bash", "/start-spark.sh"]

# Set working directory
WORKDIR /workspace
